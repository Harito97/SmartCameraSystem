{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harito/venv/py/lib/python3.11/site-packages/torchreid/reid/metrics/rank.py:11: UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
      "  warnings.warn(\n",
      "2024-01-02 22:13:37.652928: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-02 22:13:37.652980: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-02 22:13:37.654965: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-02 22:13:37.671400: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-02 22:13:39.792932: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from torchreid import models as reid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "reid_model = reid.build_model(name='hacnn', num_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: mudeep\n",
      "- params: 134,943,377\n",
      "- flops: 3,349,749,761\n",
      "torch.Size([5, 4096])\n"
     ]
    }
   ],
   "source": [
    "from torchreid.reid.utils import FeatureExtractor\n",
    "\n",
    "extractor = FeatureExtractor(\n",
    "    model_name='mudeep',\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "# image_list = [\n",
    "#     'database/data/reid_model/Duc/231231_16h26m53s_screenshot.png',\n",
    "#     'database/data/reid_model/Duc/231231_16h28m59s_screenshot.png',\n",
    "#     'database/data/reid_model/DucAnh/231231_16h28m09s_screenshot.png',\n",
    "#     'database/data/reid_model/DucAnh/231231_16h30m36s_screenshot.png'\n",
    "# ]\n",
    "\n",
    "image_list = [\n",
    "    'datatest/test_reid/tower0_0.jpg',\n",
    "    'datatest/test_reid/tower0_1.jpg',\n",
    "    'datatest/test_reid/tower0_2.jpg',\n",
    "    'datatest/test_reid/tower0_3.jpg',\n",
    "    'datatest/test_reid/tower1_0.jpg',\n",
    "]\n",
    "\n",
    "features = extractor(image_list)\n",
    "print(features.shape) # output (5, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0455, 0.0297, 0.0021,  ..., 0.0399, 0.0339, 0.0220],\n",
      "        [0.0496, 0.0268, 0.0000,  ..., 0.0390, 0.0340, 0.0225],\n",
      "        [0.0427, 0.0229, 0.0000,  ..., 0.0373, 0.0379, 0.0200],\n",
      "        [0.0487, 0.0259, 0.0000,  ..., 0.0380, 0.0370, 0.0265],\n",
      "        [0.0459, 0.0272, 0.0000,  ..., 0.0426, 0.0343, 0.0238]])\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9976)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor_0 = features[0]\n",
    "tensor_1 = features[1]\n",
    "\n",
    "cosine_similarity = torch.dot(tensor_0, tensor_1) / (torch.norm(tensor_0) * torch.norm(tensor_1))\n",
    "\n",
    "print(cosine_similarity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9900)\n"
     ]
    }
   ],
   "source": [
    "tensor_0 = features[1]\n",
    "tensor_1 = features[2]\n",
    "\n",
    "cosine_similarity = torch.dot(tensor_0, tensor_1) / (torch.norm(tensor_0) * torch.norm(tensor_1))\n",
    "\n",
    "print(cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9903)\n"
     ]
    }
   ],
   "source": [
    "tensor_0 = features[2]\n",
    "tensor_1 = features[3]\n",
    "\n",
    "cosine_similarity = torch.dot(tensor_0, tensor_1) / (torch.norm(tensor_0) * torch.norm(tensor_1))\n",
    "\n",
    "print(cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9952)\n"
     ]
    }
   ],
   "source": [
    "tensor_0 = features[1]\n",
    "tensor_1 = features[3]\n",
    "\n",
    "cosine_similarity = torch.dot(tensor_0, tensor_1) / (torch.norm(tensor_0) * torch.norm(tensor_1))\n",
    "\n",
    "print(cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9900)\n"
     ]
    }
   ],
   "source": [
    "tensor_0 = features[2]\n",
    "tensor_1 = features[4]\n",
    "\n",
    "cosine_similarity = torch.dot(tensor_0, tensor_1) / (torch.norm(tensor_0) * torch.norm(tensor_1))\n",
    "\n",
    "print(cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1204)\n"
     ]
    }
   ],
   "source": [
    "tensor_0 = features[0]\n",
    "tensor_1 = features[4]\n",
    "euclidean_distance = torch.sqrt(torch.sum((tensor_0 - tensor_1)**2))\n",
    "print(euclidean_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hai hình ảnh có chụp cùng một đối tượng không? False\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def is_same_object(image1, image2):\n",
    "  # Lấy các đặc điểm của hai hình ảnh\n",
    "  features1 = extract_features(image1)\n",
    "  features2 = extract_features(image2)\n",
    "\n",
    "  # So sánh các đặc điểm của hai hình ảnh\n",
    "  similarity = compare_features(features1, features2)\n",
    "\n",
    "  # Nếu mức độ tương đồng cao, thì hai hình ảnh chụp cùng một đối tượng\n",
    "  return similarity > 0.3\n",
    "\n",
    "def extract_features(image):\n",
    "  # Chuyển đổi hình ảnh sang định dạng HSV\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "  # Tính toán các giá trị trung bình của các kênh HSV\n",
    "  mean_h = np.mean(image[:, :, 0])\n",
    "  mean_s = np.mean(image[:, :, 1])\n",
    "  mean_v = np.mean(image[:, :, 2])\n",
    "\n",
    "  # Trả về các giá trị trung bình\n",
    "  return [mean_h, mean_s, mean_v]\n",
    "\n",
    "def compare_features(features1, features2):\n",
    "  # Chuyển đổi các danh sách thành các mảng NumPy\n",
    "  features1_np = np.array(features1)\n",
    "  features2_np = np.array(features2)\n",
    "\n",
    "  # Tính toán khoảng cách giữa các đặc điểm của hai hình ảnh\n",
    "  distance = np.linalg.norm(features1_np - features2_np)\n",
    "\n",
    "  # Trả về mức độ tương đồng\n",
    "  return 1 - distance\n",
    "\n",
    "\n",
    "# Tải hai hình ảnh\n",
    "image1 = cv2.imread('database/data/reid_model/Duc/231231_16h26m53s_screenshot.png')\n",
    "image2 = cv2.imread('database/data/reid_model/Duc/231231_16h28m59s_screenshot.png')\n",
    "image3 = cv2.imread('database/data/reid_model/DucAnh/231231_16h28m09s_screenshot.png')\n",
    "image4 = cv2.imread('database/data/reid_model/DucAnh/231231_16h30m36s_screenshot.png')\n",
    "# Xác định xem hai hình ảnh có chụp cùng một đối tượng hay không\n",
    "is_same = is_same_object(image4, image3)\n",
    "\n",
    "# In kết quả\n",
    "print(\"Hai hình ảnh có chụp cùng một đối tượng không? {}\".format(is_same))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0226, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0368]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchreid\n",
    "\n",
    "# Assuming you have an image 'input_image' with shape (3, 256, 128)\n",
    "input_image = torch.rand((1, 3, 256, 128))\n",
    "\n",
    "# Create an instance of the MuDeep model\n",
    "mudeep_model = reid.build_model(name='mudeep', num_classes=1)\n",
    "\n",
    "# Put the model in evaluation mode (if not training)\n",
    "mudeep_model.eval()\n",
    "\n",
    "# Forward pass\n",
    "output = mudeep_model(input_image)\n",
    "\n",
    "print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4096])\n"
     ]
    }
   ],
   "source": [
    "print(output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
