{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = '/home/harito/Videos/Cam1.mp4'\n",
    "# model.track(source=video_path, show=True, persist=True, classes=0, conf=0.35, tracker=\"bytetrack.yaml\")\n",
    "model.track(source=video_path, show=True, persist=True, classes=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('yolov8n-seg.pt')\n",
    "\n",
    "# Open the video file\n",
    "video_path = '/home/harito/Videos/Cam1.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Store the track history\n",
    "track_history = defaultdict(lambda: [])\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
    "        results = model.track(frame, persist=True)\n",
    "\n",
    "        # Get the boxes and track IDs\n",
    "        boxes = results[0].boxes.xywh.cpu()\n",
    "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "\n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # Plot the tracks\n",
    "        for box, track_id in zip(boxes, track_ids):\n",
    "            x, y, w, h = box\n",
    "            track = track_history[track_id]\n",
    "            track.append((float(x), float(y)))  # x, y center point\n",
    "            if len(track) > 30:  # retain 90 tracks for 90 frames\n",
    "                track.pop(0)\n",
    "\n",
    "            # Draw the tracking lines\n",
    "            points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "            cv2.polylines(annotated_frame, [points], isClosed=False, color=(0, 230, 0), thickness=10)\n",
    "\n",
    "        # Display the annotated frame\n",
    "        cv2.imshow(\"YOLOv8 Tracking\", annotated_frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO \n",
    "\n",
    "def main():\n",
    "    # Đường dẫn đến ảnh và đường dẫn đến model YOLOv8\n",
    "    image_path = '/mnt/DataK/Project/SmartCameraSystem/backend/database/data/reid_model/Duc/231231_16h26m53s_screenshot.png'\n",
    "    yolo_model_path = 'yolov8n-seg.pt'\n",
    "    frame = cv2.imread(image_path)\n",
    "    # Load model YOLOv8\n",
    "    yolo_model = YOLO(yolo_model_path)\n",
    "\n",
    "    # Run YOLOv8 inference on the frame\n",
    "    results = yolo_model(frame, classes=0, verbose=False)\n",
    "\n",
    "    # if not exist person\n",
    "    if results[0].masks is None:\n",
    "        return\n",
    "\n",
    "    # get box object\n",
    "    box = results[0].boxes[0].xyxy[0]\n",
    "    box = box.numpy().astype(int)\n",
    "\n",
    "    # background subtraction\n",
    "    mask = (results[0].masks.data[0].numpy())\n",
    "\n",
    "    cv2.imshow('Background remove', mask)\n",
    "\n",
    "    # Hiển thị ảnh\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 390 but corresponding boolean dimension is 640",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 41\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 33\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Keep the original image where the mask is 1, set to 0 where the mask is 0\u001b[39;00m\n\u001b[1;32m     32\u001b[0m object_image \u001b[38;5;241m=\u001b[39m bounding_box\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 33\u001b[0m \u001b[43mobject_image\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Show the result\u001b[39;00m\n\u001b[1;32m     36\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject Only\u001b[39m\u001b[38;5;124m'\u001b[39m, object_image)\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 390 but corresponding boolean dimension is 640"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO \n",
    "\n",
    "def main():\n",
    "    # Đường dẫn đến ảnh và đường dẫn đến model YOLOv8\n",
    "    image_path = '/mnt/DataK/Project/SmartCameraSystem/backend/database/data/reid_model/Duc/231231_16h26m53s_screenshot.png'\n",
    "    yolo_model_path = 'yolov8n-seg.pt'\n",
    "    frame = cv2.imread(image_path)\n",
    "\n",
    "    # Load model YOLOv8\n",
    "    yolo_model = YOLO(yolo_model_path)\n",
    "\n",
    "    # Run YOLOv8 inference on the frame\n",
    "    results = yolo_model(frame, classes=0, verbose=False)\n",
    "\n",
    "    # if not exist person\n",
    "    if results[0].masks is None:\n",
    "        return\n",
    "\n",
    "    # get box object\n",
    "    x, y, w, h = results[0].boxes.xywh.cpu()[0]\n",
    "    xmin = int(x - w / 2)\n",
    "    ymin = int(y - h / 2)\n",
    "    xmax = int(x + w / 2)\n",
    "    ymax = int(y + h / 2)\n",
    "    bounding_box = frame[ymin:ymax, xmin:xmax, :]\n",
    "    # background subtraction\n",
    "    mask = (results[0].masks.data[0].numpy())\n",
    "\n",
    "    # Keep the original image where the mask is 1, set to 0 where the mask is 0\n",
    "    object_image = bounding_box.copy()\n",
    "    object_image[mask == 0] = 0\n",
    "\n",
    "    # Show the result\n",
    "    cv2.imshow('Object Only', object_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 654 but corresponding boolean dimension is 640",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 45\u001b[0m\n\u001b[1;32m     41\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimwrite(output_path, object_image)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 45\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 33\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Resize mask to match the size of the region of interest (ROI)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# mask = cv2.resize(mask, (box[2] - box[0], box[3] - box[1]))\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Keep the original image where the mask is 1, set to 0 where the mask is 0\u001b[39;00m\n\u001b[1;32m     32\u001b[0m object_image \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 33\u001b[0m \u001b[43mobject_image\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43mbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43mbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Show the result\u001b[39;00m\n\u001b[1;32m     36\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject Only\u001b[39m\u001b[38;5;124m'\u001b[39m, object_image)\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 654 but corresponding boolean dimension is 640"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO \n",
    "\n",
    "def main():\n",
    "    # Đường dẫn đến ảnh và đường dẫn đến model YOLOv8\n",
    "    image_path = '/mnt/DataK/Project/SmartCameraSystem/backend/database/data/reid_model/Duc/231231_16h28m59s_screenshot.png'\n",
    "    yolo_model_path = 'yolov8n-seg.pt'\n",
    "    frame = cv2.imread(image_path)\n",
    "\n",
    "    # Load model YOLOv8\n",
    "    yolo_model = YOLO(yolo_model_path)\n",
    "\n",
    "    # Run YOLOv8 inference on the frame\n",
    "    results = yolo_model(frame, classes=0, verbose=False)\n",
    "\n",
    "    # if not exist person\n",
    "    if results[0].masks is None:\n",
    "        return\n",
    "\n",
    "    # get box object\n",
    "    box = results[0].boxes[0].xyxy[0]\n",
    "    box = box.numpy().astype(int)\n",
    "\n",
    "    # background subtraction\n",
    "    mask = (results[0].masks.data[0].numpy())\n",
    "\n",
    "    # Resize mask to match the size of the region of interest (ROI)\n",
    "    # mask = cv2.resize(mask, (box[2] - box[0], box[3] - box[1]))\n",
    "\n",
    "    # Keep the original image where the mask is 1, set to 0 where the mask is 0\n",
    "    object_image = frame.copy()\n",
    "    object_image[box[1]:box[3], box[0]:box[2]][mask == 0] = 0\n",
    "\n",
    "    # Show the result\n",
    "    cv2.imshow('Object Only', object_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    output_path = 'Duc2.png'\n",
    "    cv2.imwrite(output_path, object_image)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
