{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luồng camera để truyền frame ảnh lên cho YOLO detect <phía producer id = 1>\n",
    "import cv2\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "bootstrap_servers = 'localhost:9092'\n",
    "topic = 'video_frames'\n",
    "producer1 = KafkaProducer(bootstrap_servers=bootstrap_servers)\n",
    "\n",
    "# Dùng OpenCV để phân tách các frame ảnh \n",
    "video_path = 'VideoSend_0.mkv'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Chuyển frame ảnh thành kiểu byte (đảm bảo đúng kiểu dữ liệu tham số đầu vào)\n",
    "    _, img_encoded = cv2.imencode('.png', frame)\n",
    "    img_bytes = img_encoded.tobytes()\n",
    "\n",
    "    # Dùng producer send ảnh đến topic Kafka\n",
    "    producer1.send(topic, value=img_bytes)\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luồng camera để truyền frame ảnh lên cho YOLO detect <phía consumer id = 1>\n",
    "import cv2\n",
    "import numpy as np\n",
    "from kafka import KafkaConsumer\n",
    "\n",
    "# Khởi tạo consumer\n",
    "bootstrap_servers = 'localhost:9092'\n",
    "topic = 'video_frames'\n",
    "consumer1 = KafkaConsumer(topic, bootstrap_servers=bootstrap_servers)\n",
    "\n",
    "# Tạo cửa số nhờ OpenCV để hiện thị các frame ảnh\n",
    "cv2.namedWindow('Video', cv2.WINDOW_NORMAL)\n",
    "\n",
    "for msg in consumer1:\n",
    "    img_bytes = msg.value\n",
    "\n",
    "    # Convert bytes to image\n",
    "    nparr = np.frombuffer(img_bytes, dtype=np.uint8)\n",
    "    frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "    # frame sẽ là một mảng NumPy có kiểu dữ liệu là numpy.ndarray và có thể được truy cập thông qua các chỉ số mảng để lấy các giá trị pixel.\n",
    "\n",
    "    # Display frame\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 12 persons, 3076.7ms\n",
      "Speed: 7.0ms preprocess, 3076.7ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "image = Image.open(\"0.jpg\")\n",
    "\n",
    "from ultralytics import YOLO\n",
    "# Load the YOLOv8 model\n",
    "yolo_model = YOLO('yolov8x.pt')\n",
    "predict = yolo_model.predict(source=image)\n",
    "bounding_boxes = predict[0].boxes.xywh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
