{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: 1 ảnh png jpg chuyển thành Tensor\n",
    "# output: 1 list các bounding boxes cho reID model \n",
    "from PIL import Image\n",
    "image = Image.open(\"0.jpg\")\n",
    "\n",
    "from ultralytics import YOLO\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('yolov8x.pt')\n",
    "predict = model.predict(source=image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(predict[0]))\n",
    "# print(len(predict))\n",
    "# print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy thông tin bounding boxes từ results\n",
    "# print(dir(predict[0]))\n",
    "# boxes = predict[0].orig_img\n",
    "# print(boxes)\n",
    "\n",
    "# boxes = predict[0].boxes\n",
    "# print(type(boxes))\n",
    "# print(boxes)\n",
    "\n",
    "# print(len(boxes))           # height\n",
    "# print(len(boxes[0]))        # width\n",
    "# print(len(boxes[0][0]))     # RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_boxes = predict[0].boxes.xywh\n",
    "print(bounding_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "yolo_model = YOLO('yolov8x.pt')\n",
    "\n",
    "import torchreid\n",
    "reid_model = torchreid.models.build_model(\n",
    "    name='mudeep',\n",
    "    num_classes=1000,\n",
    "    pretrained=True\n",
    ")\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "def detect_objects(image_path, yolo_model):\n",
    "    # Load ảnh\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "\n",
    "    # Sử dụng YOLO để xác định vùng chứa object\n",
    "    results = yolo_model(img)\n",
    "\n",
    "    # Lấy thông tin về object và bounding box\n",
    "    boxes = results[0].boxes.xywh   # tensor\n",
    "\n",
    "    # Cắt và lưu các vùng chứa object\n",
    "    object_images = []\n",
    "    for box in boxes:\n",
    "        xmin, ymin, width, height = map(int, box)\n",
    "        xmax = xmin + width\n",
    "        ymax = ymin + height\n",
    "        object_img = img.crop((xmin, ymin, xmax, ymax))\n",
    "        object_images.append(object_img)\n",
    "\n",
    "    return object_images\n",
    "\n",
    "from torchvision import transforms\n",
    "def extract_features(image, reid_model):\n",
    "    # Load ảnh và tiền xử lý nó để phù hợp với mô hình\n",
    "    img = image.convert('RGB')\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((256, 128)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    img = preprocess(img).unsqueeze(0)\n",
    "\n",
    "    # Đưa ảnh qua mô hình để lấy đặc trưng\n",
    "    with torch.no_grad():\n",
    "        features = reid_model.featuremaps(img)\n",
    "\n",
    "    # return features.squeeze().numpy()\n",
    "    return features\n",
    "\n",
    "# def main():\n",
    "#     from sklearn.metrics.pairwise import cosine_similarity\n",
    "#     # Đường dẫn đến ảnh 1 và ảnh 2\n",
    "#     image_path_1 = '0.jpg'\n",
    "#     image_path_2 = '1.jpg'\n",
    "\n",
    "#     # Dùng YOLO để xác định vùng chứa object trên ảnh 1 và ảnh 2\n",
    "#     object_images_1 = detect_objects(image_path_1, yolo_model)\n",
    "#     object_images_2 = detect_objects(image_path_2, yolo_model)\n",
    "\n",
    "#     # Trích xuất vector đặc trưng từ reid_model cho từng vùng chứa object\n",
    "#     features_1 = [extract_features(img, reid_model) for img in object_images_1]\n",
    "#     features_2 = [extract_features(img, reid_model) for img in object_images_2]\n",
    "\n",
    "#     # # So sánh các vector đặc trưng\n",
    "#     # for i, feature_1 in enumerate(features_1):\n",
    "#     #     for j, feature_2 in enumerate(features_2):\n",
    "#     #         # Lấy mảng numpy từ tensor và làm phẳng\n",
    "#     #         feature_1 = feature_1[0].ravel()\n",
    "#     #         feature_2 = feature_2[0].ravel()\n",
    "\n",
    "#     #         # Sử dụng phương pháp so sánh phù hợp (ví dụ: cosine similarity)\n",
    "#     #         similarity_score = cosine_similarity(feature_1.reshape(1, -1), feature_2.reshape(1, -1))\n",
    "\n",
    "#     #         # In kết quả\n",
    "#     #         print(f'Similarity between object {i+1} in image 1 and object {j+1} in image 2: {similarity_score[0, 0]}')\n",
    "\n",
    "#     print(features_1)\n",
    "#     print(features_2)\n",
    "#     print(type(features_1))\n",
    "#     print(len(features_1))\n",
    "#     print(len(features_2))\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x640 4 persons, 1 car, 2508.0ms\n",
      "Speed: 5.7ms preprocess, 2508.0ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 320x640 4 persons, 2444.3ms\n",
      "Speed: 5.0ms preprocess, 2444.3ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Đường dẫn đến ảnh 1 và ảnh 2\n",
    "image_path_1 = '0.jpg'\n",
    "image_path_2 = '1.jpg'\n",
    "# Dùng YOLO để xác định vùng chứa object trên ảnh 1 và ảnh 2\n",
    "object_images_1 = detect_objects(image_path_1, yolo_model)\n",
    "object_images_2 = detect_objects(image_path_2, yolo_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.Image.Image'>\n",
      "(845, 594)\n"
     ]
    }
   ],
   "source": [
    "print(type(object_images_1[0]))\n",
    "print(object_images_1[0].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trích xuất vector đặc trưng từ reid_model cho từng vùng chứa object\n",
    "features_1 = [extract_features(img, reid_model) for img in object_images_1]\n",
    "features_2 = [extract_features(img, reid_model) for img in object_images_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from siamese_network import SiameseNetwork\n",
    "sinetwork = SiameseNetwork()\n",
    "# compare = [sinetwork.forward(i, j) for i in object_images_1 for j in object_images_2]\n",
    "\n",
    "# Định nghĩa một hàm chuyển đổi hình ảnh thành tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Duyệt qua từng cặp hình ảnh và tính toán độ tương đồng\n",
    "compare = [\n",
    "    sinetwork.forward(transform(i).unsqueeze(0), transform(j).unsqueeze(0))\n",
    "    for i, j in zip(object_images_1, object_images_2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.7\n",
    "\n",
    "for i in range(len(features_1)):\n",
    "    for j in range(len(features_2)):\n",
    "        # features_1 và features_2 là các đặc trưng được trích xuất từ hai ảnh\n",
    "        similarity_score = cosine_similarity(features_1[i].reshape(1, -1), features_2[j].reshape(1, -1))\n",
    "\n",
    "        # In kết quả\n",
    "        print(f'features_1[{i}] and features_2[{j}]: {similarity_score[0, 0]}')\n",
    "\n",
    "        if similarity_score >= threshold:\n",
    "            print(f\"features_1[{i}] is similar to features_2[{j}].\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_1[0].shape)\n",
    "print(features_2[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features_1:\n",
    "    print(feature)\n",
    "    print(len(feature))\n",
    "    print(type(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(features_1))\n",
    "print(features_1[0][0])\n",
    "print(features_1[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(features_2))\n",
    "print(features_2[0][0])\n",
    "print(features_2[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(features_1), len(features_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(object_images_1)\n",
    "print(len(object_images_1))\n",
    "print(type(object_images_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n",
    "# !pip install fastreid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
